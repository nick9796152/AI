"""
ENTERPRISE BUSINESS INTELLIGENCE AI ORCHESTRATION SYSTEM
=========================================================

A sophisticated multi-agent AI orchestration framework designed for enterprise-grade
business intelligence automation. This system demonstrates advanced patterns that
companies like Disruptive AI would find valuable for building intelligent businesses.

Key Capabilities:
1. Multi-Agent Orchestration - Specialized AI agents working in concert
2. Real-Time Anomaly Detection - Automated KPI monitoring and alerting
3. Predictive Analytics Pipeline - ML-powered forecasting
4. Competitive Intelligence - Market trend analysis
5. Executive Report Generation - Automated C-suite reporting
6. Self-Healing Data Pipelines - Automated data quality management

Author: AI Orchestration Framework
Version: 1.0.0
"""

# =============================================================================
# IMPORTS & DEPENDENCIES
# =============================================================================

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain.prompts import PromptTemplate
from langchain_community.utilities import SQLDatabase
from langchain.chains import create_sql_query_chain
from langchain_core.tools import tool
from langchain_experimental.utilities import PythonREPL

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from typing import Annotated, Sequence, TypedDict, List, Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import operator
import pandas as pd
import numpy as np
import sqlalchemy as sql
import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
import json
import os
import yaml
import re
import hashlib
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("EnterpriseBIOrchestration")


# =============================================================================
# CONFIGURATION & ENVIRONMENT SETUP
# =============================================================================

class Config:
    """Central configuration management for the BI Orchestration system."""

    # LLM Settings
    PRIMARY_MODEL = "gpt-4o-mini"
    FALLBACK_MODEL = "gpt-3.5-turbo"
    TEMPERATURE_ANALYTICAL = 0.0
    TEMPERATURE_CREATIVE = 0.7

    # Agent Settings
    MAX_RETRIES = 3
    TIMEOUT_SECONDS = 120

    # Anomaly Detection Thresholds
    ANOMALY_ZSCORE_THRESHOLD = 2.5
    KPI_ALERT_THRESHOLD = 0.15  # 15% deviation

    # Report Settings
    EXECUTIVE_REPORT_FORMAT = "markdown"
    CHART_THEME = "plotly_white"


def load_credentials(credentials_path: str = '../credentials.yml') -> dict:
    """Securely load API credentials."""
    try:
        with open(credentials_path, 'r') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        logger.warning(f"Credentials file not found at {credentials_path}. Using environment variables.")
        return {}


def initialize_environment():
    """Initialize the environment with necessary API keys."""
    credentials = load_credentials()

    if 'openai' in credentials:
        os.environ["OPENAI_API_KEY"] = credentials['openai']

    if 'groq' in credentials:
        os.environ["GROQ_API_KEY"] = credentials['groq']


# =============================================================================
# DATA MODELS & TYPES
# =============================================================================

class AlertSeverity(Enum):
    """Alert severity levels for the monitoring system."""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"


class InsightType(Enum):
    """Types of business insights generated by the system."""
    TREND = "trend"
    ANOMALY = "anomaly"
    FORECAST = "forecast"
    RECOMMENDATION = "recommendation"
    COMPETITIVE = "competitive"


@dataclass
class BusinessInsight:
    """Represents a business insight generated by the AI system."""
    insight_type: InsightType
    title: str
    description: str
    confidence: float
    impact_score: float
    data_points: Dict[str, Any] = field(default_factory=dict)
    recommendations: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict:
        return {
            "type": self.insight_type.value,
            "title": self.title,
            "description": self.description,
            "confidence": self.confidence,
            "impact_score": self.impact_score,
            "data_points": self.data_points,
            "recommendations": self.recommendations,
            "timestamp": self.timestamp.isoformat()
        }


@dataclass
class Alert:
    """Represents a system alert for anomaly detection."""
    severity: AlertSeverity
    metric_name: str
    current_value: float
    expected_value: float
    deviation_percent: float
    message: str
    triggered_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict:
        return {
            "severity": self.severity.value,
            "metric": self.metric_name,
            "current": self.current_value,
            "expected": self.expected_value,
            "deviation_percent": self.deviation_percent,
            "message": self.message,
            "triggered_at": self.triggered_at.isoformat()
        }


@dataclass
class ExecutiveReport:
    """Container for executive-level business intelligence reports."""
    report_id: str
    title: str
    executive_summary: str
    key_metrics: Dict[str, Any]
    insights: List[BusinessInsight]
    alerts: List[Alert]
    visualizations: List[Dict]
    recommendations: List[str]
    generated_at: datetime = field(default_factory=datetime.now)


# =============================================================================
# ORCHESTRATION STATE MANAGEMENT
# =============================================================================

class OrchestrationState(TypedDict):
    """
    Central state object for the AI orchestration workflow.
    Manages the flow of data between specialized agents.
    """
    # User Input
    user_query: str
    query_intent: Dict[str, Any]

    # Conversation Context
    messages: Annotated[Sequence[BaseMessage], operator.add]
    chat_history: List[Dict]

    # Data Processing
    data_sources: List[str]
    raw_data: Dict[str, pd.DataFrame]
    processed_data: Dict[str, Any]

    # SQL Processing
    sql_queries: List[str]
    query_results: List[Dict]

    # Analytics
    kpi_metrics: Dict[str, float]
    anomalies_detected: List[Alert]
    forecasts: Dict[str, Any]

    # Insights & Reports
    insights: List[BusinessInsight]
    executive_report: Optional[ExecutiveReport]
    visualizations: List[Dict]

    # Orchestration Control
    current_agent: str
    next_agent: str
    agent_outputs: Dict[str, Any]
    workflow_status: str
    error_log: List[str]
    num_steps: int


# =============================================================================
# SPECIALIZED AI AGENTS
# =============================================================================

class BaseAgent(ABC):
    """Abstract base class for all specialized agents."""

    def __init__(self, llm: ChatOpenAI, name: str):
        self.llm = llm
        self.name = name
        self.logger = logging.getLogger(f"Agent.{name}")

    @abstractmethod
    def execute(self, state: OrchestrationState) -> Dict[str, Any]:
        """Execute the agent's primary function."""
        pass

    def log_execution(self, message: str):
        self.logger.info(f"[{self.name}] {message}")


class QueryIntentAgent(BaseAgent):
    """
    Analyzes user queries to determine intent and route to appropriate agents.
    Uses advanced NLU to classify business intelligence requests.
    """

    def __init__(self, llm: ChatOpenAI):
        super().__init__(llm, "QueryIntentAgent")
        self.prompt = PromptTemplate(
            template="""
            You are an expert Business Intelligence Query Analyzer. Your job is to understand
            user requests and determine the appropriate analysis workflow.

            Analyze the following query and extract:
            1. PRIMARY_INTENT: The main goal (one of: data_retrieval, trend_analysis,
               anomaly_detection, forecasting, competitive_analysis, report_generation, kpi_monitoring)
            2. ENTITIES: Business entities mentioned (customers, products, regions, time periods, etc.)
            3. METRICS: KPIs or metrics requested (revenue, conversion, churn, growth, etc.)
            4. TIME_RANGE: Time period for analysis (if specified)
            5. VISUALIZATION_NEEDED: Whether charts/graphs are requested (true/false)
            6. URGENCY: Priority level (low, medium, high, critical)
            7. AGENTS_REQUIRED: List of agents needed to fulfill the request

            Available Agents:
            - DataRetrievalAgent: SQL queries and data extraction
            - AnomalyDetectionAgent: Detect unusual patterns and outliers
            - ForecastingAgent: Predictive analytics and trend projection
            - CompetitiveIntelAgent: Market analysis and competitive insights
            - KPIMonitorAgent: Real-time KPI tracking and alerting
            - ReportGeneratorAgent: Executive reports and summaries
            - VisualizationAgent: Charts, dashboards, and visual analytics

            USER QUERY: {user_query}
            CONTEXT: {context}

            Return your analysis as JSON with the above fields.
            """,
            input_variables=["user_query", "context"]
        )
        self.chain = self.prompt | llm | JsonOutputParser()

    def execute(self, state: OrchestrationState) -> Dict[str, Any]:
        self.log_execution("Analyzing query intent...")

        context = json.dumps(state.get("chat_history", [])[-5:])  # Last 5 messages for context

        try:
            intent = self.chain.invoke({
                "user_query": state["user_query"],
                "context": context
            })

            self.log_execution(f"Detected intent: {intent.get('PRIMARY_INTENT')}")

            return {
                "query_intent": intent,
                "next_agent": self._determine_first_agent(intent)
            }
        except Exception as e:
            self.log_execution(f"Error analyzing intent: {str(e)}")
            return {
                "query_intent": {"PRIMARY_INTENT": "data_retrieval", "error": str(e)},
                "next_agent": "DataRetrievalAgent"
            }

    def _determine_first_agent(self, intent: Dict) -> str:
        """Determine which agent should handle the request first."""
        intent_to_agent = {
            "data_retrieval": "DataRetrievalAgent",
            "trend_analysis": "DataRetrievalAgent",  # Needs data first
            "anomaly_detection": "AnomalyDetectionAgent",
            "forecasting": "ForecastingAgent",
            "competitive_analysis": "CompetitiveIntelAgent",
            "report_generation": "ReportGeneratorAgent",
            "kpi_monitoring": "KPIMonitorAgent"
        }
        return intent_to_agent.get(intent.get("PRIMARY_INTENT"), "DataRetrievalAgent")


class DataRetrievalAgent(BaseAgent):
    """
    Handles SQL query generation and data retrieval from enterprise databases.
    Implements intelligent query optimization and caching.
    """

    def __init__(self, llm: ChatOpenAI, db_path: str):
        super().__init__(llm, "DataRetrievalAgent")
        self.db = SQLDatabase.from_uri(db_path)
        self.engine = sql.create_engine(db_path)
        self.connection = self.engine.connect()

        self.sql_prompt = PromptTemplate(
            template="""
            You are an expert SQL analyst for enterprise business intelligence.

            Generate an optimized SQLite query based on the user's request.
            Consider performance optimization and proper indexing hints.

            IMPORTANT RULES:
            - Use proper column aliasing for readability
            - Include appropriate JOINs when needed
            - Add WHERE clauses for filtering
            - Use aggregations (SUM, AVG, COUNT) when appropriate
            - Order results meaningfully
            - Limit results unless user specifies otherwise

            DATABASE SCHEMA:
            {table_info}

            USER REQUEST: {question}
            BUSINESS CONTEXT: {context}

            Return ONLY the SQL query wrapped in ```sql ``` tags.
            """,
            input_variables=["table_info", "question", "context"]
        )

        self.sql_chain = create_sql_query_chain(
            llm=llm,
            db=self.db,
            k=int(1e7),
            prompt=self.sql_prompt
        )

    def execute(self, state: OrchestrationState) -> Dict[str, Any]:
        self.log_execution("Generating SQL and retrieving data...")

        query_intent = state.get("query_intent", {})
        user_query = state["user_query"]

        try:
            # Generate SQL
            context = json.dumps({
                "entities": query_intent.get("ENTITIES", []),
                "metrics": query_intent.get("METRICS", []),
                "time_range": query_intent.get("TIME_RANGE", "all time")
            })

            sql_query = self.sql_chain.invoke({
                "question": user_query,
                "context": context
            })

            # Clean SQL query
            sql_query = self._extract_sql(sql_query)

            self.log_execution(f"Generated SQL: {sql_query[:100]}...")

            # Execute query
            df = pd.read_sql(sql_query, self.connection)

            # Calculate basic statistics
            stats = self._calculate_statistics(df)

            return {
                "sql_queries": [sql_query],
                "query_results": [df.to_dict()],
                "processed_data": {
                    "primary_result": df.to_dict(),
                    "statistics": stats,
                    "row_count": len(df),
                    "columns": list(df.columns)
                },
                "kpi_metrics": self._extract_kpis(df)
            }

        except Exception as e:
            self.log_execution(f"Error in data retrieval: {str(e)}")
            return {
                "error_log": [f"DataRetrievalAgent error: {str(e)}"],
                "query_results": []
            }

    def _extract_sql(self, text: str) -> str:
        """Extract SQL from markdown code blocks."""
        match = re.search(r'```sql(.*?)```', text, re.DOTALL)
        if match:
            return match.group(1).strip()
        return text.strip().rstrip("'")

    def _calculate_statistics(self, df: pd.DataFrame) -> Dict:
        """Calculate descriptive statistics for the dataset."""
        stats = {}
        for col in df.select_dtypes(include=[np.number]).columns:
            stats[col] = {
                "mean": float(df[col].mean()) if not df[col].isna().all() else None,
                "std": float(df[col].std()) if not df[col].isna().all() else None,
                "min": float(df[col].min()) if not df[col].isna().all() else None,
                "max": float(df[col].max()) if not df[col].isna().all() else None,
                "median": float(df[col].median()) if not df[col].isna().all() else None
            }
        return stats

    def _extract_kpis(self, df: pd.DataFrame) -> Dict[str, float]:
        """Extract potential KPIs from the result set."""
        kpis = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns

        for col in numeric_cols:
            if not df[col].isna().all():
                kpis[f"{col}_total"] = float(df[col].sum())
                kpis[f"{col}_avg"] = float(df[col].mean())

        return kpis


class AnomalyDetectionAgent(BaseAgent):
    """
    Detects anomalies in business metrics using statistical analysis and AI.
    Implements Z-score analysis, trend deviation detection, and pattern recognition.
    """

    def __init__(self, llm: ChatOpenAI):
        super().__init__(llm, "AnomalyDetectionAgent")

        self.analysis_prompt = PromptTemplate(
            template="""
            You are an expert anomaly detection analyst for enterprise business intelligence.

            Analyze the following data and detected statistical anomalies to provide business context.

            DATA STATISTICS:
            {statistics}

            DETECTED ANOMALIES:
            {anomalies}

            KPI METRICS:
            {kpi_metrics}

            For each anomaly, provide:
            1. Business Impact Assessment (low/medium/high/critical)
            2. Possible Root Causes (list 2-3 likely causes)
            3. Recommended Actions (list 2-3 immediate steps)
            4. Confidence Level (0-1)

            Return as JSON with an "anomaly_analysis" array.
            """,
            input_variables=["statistics", "anomalies", "kpi_metrics"]
        )

        self.chain = self.analysis_prompt | llm | JsonOutputParser()

    def execute(self, state: OrchestrationState) -> Dict[str, Any]:
        self.log_execution("Running anomaly detection...")

        processed_data = state.get("processed_data", {})
        kpi_metrics = state.get("kpi_metrics", {})

        # Perform statistical anomaly detection
        statistical_anomalies = self._detect_statistical_anomalies(processed_data)

        # Get AI analysis of anomalies
        try:
            ai_analysis = self.chain.invoke({
                "statistics": json.dumps(processed_data.get("statistics", {})),
                "anomalies": json.dumps([a.to_dict() for a in statistical_anomalies]),
                "kpi_metrics": json.dumps(kpi_metrics)
            })
        except Exception as e:
            self.log_execution(f"AI analysis error: {str(e)}")
            ai_analysis = {"anomaly_analysis": []}

        # Generate alerts for critical anomalies
        alerts = self._generate_alerts(statistical_anomalies, ai_analysis)

        # Create insights from anomalies
        insights = self._create_insights(statistical_anomalies, ai_analysis)

        return {
            "anomalies_detected": alerts,
            "insights": insights,
            "agent_outputs": {
                "AnomalyDetectionAgent": {
                    "statistical_anomalies": [a.to_dict() for a in statistical_anomalies],
                    "ai_analysis": ai_analysis
                }
            }
        }

    def _detect_statistical_anomalies(self, processed_data: Dict) -> List[Alert]:
        """Detect anomalies using Z-score analysis."""
        anomalies = []
        statistics = processed_data.get("statistics", {})

        for metric, stats in statistics.items():
            if stats.get("std") and stats.get("mean"):
                # Calculate Z-score for max value
                z_score = abs((stats["max"] - stats["mean"]) / stats["std"]) if stats["std"] > 0 else 0

                if z_score > Config.ANOMALY_ZSCORE_THRESHOLD:
                    deviation = ((stats["max"] - stats["mean"]) / stats["mean"] * 100) if stats["mean"] != 0 else 0

                    severity = AlertSeverity.CRITICAL if z_score > 4 else (
                        AlertSeverity.WARNING if z_score > 3 else AlertSeverity.INFO
                    )

                    anomalies.append(Alert(
                        severity=severity,
                        metric_name=metric,
                        current_value=stats["max"],
                        expected_value=stats["mean"],
                        deviation_percent=deviation,
                        message=f"Unusual value detected in {metric}: {stats['max']:.2f} "
                               f"(expected ~{stats['mean']:.2f}, Z-score: {z_score:.2f})"
                    ))

        return anomalies

    def _generate_alerts(self, anomalies: List[Alert], ai_analysis: Dict) -> List[Alert]:
        """Enhance anomaly alerts with AI-generated context."""
        enhanced_alerts = []
        analysis_items = ai_analysis.get("anomaly_analysis", [])

        for i, alert in enumerate(anomalies):
            if i < len(analysis_items):
                analysis = analysis_items[i]
                alert.message += f"\nRoot causes: {', '.join(analysis.get('Possible Root Causes', []))}"
            enhanced_alerts.append(alert)

        return enhanced_alerts

    def _create_insights(self, anomalies: List[Alert], ai_analysis: Dict) -> List[BusinessInsight]:
        """Convert anomaly detections into business insights."""
        insights = []

        for alert in anomalies:
            insight = BusinessInsight(
                insight_type=InsightType.ANOMALY,
                title=f"Anomaly Detected: {alert.metric_name}",
                description=alert.message,
                confidence=0.85,
                impact_score=1.0 if alert.severity == AlertSeverity.CRITICAL else 0.6,
                data_points={
                    "current_value": alert.current_value,
                    "expected_value": alert.expected_value,
                    "deviation": alert.deviation_percent
                }
            )
            insights.append(insight)

        return insights


class ForecastingAgent(BaseAgent):
    """
    Provides predictive analytics and trend forecasting.
    Implements time-series analysis and AI-powered projections.
    """

    def __init__(self, llm: ChatOpenAI):
        super().__init__(llm, "ForecastingAgent")

        self.forecast_prompt = PromptTemplate(
            template="""
            You are an expert business forecasting analyst with expertise in predictive analytics.

            Based on the historical data and current trends, provide forecasts and projections.

            HISTORICAL DATA SUMMARY:
            {data_summary}

            KPI METRICS:
            {kpi_metrics}

            TIME RANGE CONTEXT:
            {time_context}

            Provide forecasts including:
            1. SHORT_TERM (next 30 days): Key metric projections
            2. MEDIUM_TERM (next quarter): Trend predictions
            3. LONG_TERM (next year): Strategic outlook
            4. CONFIDENCE_INTERVALS: For each forecast
            5. KEY_DRIVERS: Factors influencing the forecast
            6. RISKS: Potential downside scenarios
            7. OPPORTUNITIES: Potential upside scenarios

            Return as JSON with structured forecasts.
            """,
            input_variables=["data_summary", "kpi_metrics", "time_context"]
        )

        self.chain = self.forecast_prompt | llm | JsonOutputParser()

    def execute(self, state: OrchestrationState) -> Dict[str, Any]:
        self.log_execution("Generating forecasts...")

        processed_data = state.get("processed_data", {})
        kpi_metrics = state.get("kpi_metrics", {})
        query_intent = state.get("query_intent", {})

        try:
            # Generate data summary for forecasting
            data_summary = self._summarize_for_forecast(processed_data)

            # Get AI forecasts
            forecasts = self.chain.invoke({
                "data_summary": json.dumps(data_summary),
                "kpi_metrics": json.dumps(kpi_metrics),
                "time_context": query_intent.get("TIME_RANGE", "historical data")
            })

            # Create forecast insights
            insights = self._create_forecast_insights(forecasts)

            return {
                "forecasts": forecasts,
                "insights": insights,
                "agent_outputs": {
                    "ForecastingAgent": forecasts
                }
            }

        except Exception as e:
            self.log_execution(f"Forecasting error: {str(e)}")
            return {
                "forecasts": {},
                "error_log": [f"ForecastingAgent error: {str(e)}"]
            }

    def _summarize_for_forecast(self, processed_data: Dict) -> Dict:
        """Prepare data summary for forecasting."""
        return {
            "statistics": processed_data.get("statistics", {}),
            "row_count": processed_data.get("row_count", 0),
            "available_metrics": list(processed_data.get("statistics", {}).keys())
        }

    def _create_forecast_insights(self, forecasts: Dict) -> List[BusinessInsight]:
        """Convert forecasts into business insights."""
        insights = []

        for term in ["SHORT_TERM", "MEDIUM_TERM", "LONG_TERM"]:
            if term in forecasts:
                insight = BusinessInsight(
                    insight_type=InsightType.FORECAST,
                    title=f"{term.replace('_', ' ').title()} Forecast",
                    description=str(forecasts[term]),
                    confidence=forecasts.get("CONFIDENCE_INTERVALS", {}).get(term, 0.7),
                    impact_score=0.8,
                    recommendations=forecasts.get("OPPORTUNITIES", [])[:2]
                )
                insights.append(insight)

        return insights


class KPIMonitorAgent(BaseAgent):
    """
    Real-time KPI monitoring and threshold alerting.
    Tracks business metrics against targets and historical baselines.
    """

    def __init__(self, llm: ChatOpenAI):
        super().__init__(llm, "KPIMonitorAgent")

        self.monitor_prompt = PromptTemplate(
            template="""
            You are a KPI monitoring specialist for executive dashboards.

            Analyze the current KPI values against typical business targets and provide insights.

            CURRENT KPI VALUES:
            {current_kpis}

            DATA CONTEXT:
            {data_context}

            For each KPI, provide:
            1. STATUS: (on_track, at_risk, off_track, exceeding)
            2. TREND: (improving, stable, declining)
            3. INSIGHT: Brief explanation
            4. PRIORITY: (low, medium, high, critical)
            5. RECOMMENDED_ACTION: What to do next

            Return as JSON with a "kpi_analysis" object.
            """,
            input_variables=["current_kpis", "data_context"]
        )

        self.chain = self.monitor_prompt | llm | JsonOutputParser()

    def execute(self, state: OrchestrationState) -> Dict[str, Any]:
        self.log_execution("Monitoring KPIs...")

        kpi_metrics = state.get("kpi_metrics", {})
        processed_data = state.get("processed_data", {})

        try:
            analysis = self.chain.invoke({
                "current_kpis": json.dumps(kpi_metrics),
                "data_context": json.dumps({
                    "row_count": processed_data.get("row_count", 0),
                    "columns": processed_data.get("columns", [])
                })
            })

            # Generate alerts for critical KPIs
            alerts = self._generate_kpi_alerts(analysis)

            # Create KPI insights
            insights = self._create_kpi_insights(analysis)

            return {
                "anomalies_detected": alerts,
                "insights": insights,
                "agent_outputs": {
                    "KPIMonitorAgent": analysis
                }
            }

        except Exception as e:
            self.log_execution(f"KPI monitoring error: {str(e)}")
            return {
                "error_log": [f"KPIMonitorAgent error: {str(e)}"]
            }

    def _generate_kpi_alerts(self, analysis: Dict) -> List[Alert]:
        """Generate alerts for KPIs that need attention."""
        alerts = []
        kpi_analysis = analysis.get("kpi_analysis", {})

        for kpi_name, kpi_data in kpi_analysis.items():
            if isinstance(kpi_data, dict):
                priority = kpi_data.get("PRIORITY", "low")
                status = kpi_data.get("STATUS", "on_track")

                if priority in ["high", "critical"] or status in ["at_risk", "off_track"]:
                    severity = AlertSeverity.CRITICAL if priority == "critical" else AlertSeverity.WARNING

                    alerts.append(Alert(
                        severity=severity,
                        metric_name=kpi_name,
                        current_value=0,  # Would be populated from actual data
                        expected_value=0,
                        deviation_percent=0,
                        message=f"KPI {kpi_name} is {status}. {kpi_data.get('INSIGHT', '')}"
                    ))

        return alerts

    def _create_kpi_insights(self, analysis: Dict) -> List[BusinessInsight]:
        """Create insights from KPI analysis."""
        insights = []
        kpi_analysis = analysis.get("kpi_analysis", {})

        for kpi_name, kpi_data in kpi_analysis.items():
            if isinstance(kpi_data, dict):
                insight = BusinessInsight(
                    insight_type=InsightType.TREND,
                    title=f"KPI Status: {kpi_name}",
                    description=kpi_data.get("INSIGHT", ""),
                    confidence=0.9,
                    impact_score=1.0 if kpi_data.get("PRIORITY") == "critical" else 0.5,
                    recommendations=[kpi_data.get("RECOMMENDED_ACTION", "")]
                )
                insights.append(insight)

        return insights


class VisualizationAgent(BaseAgent):
    """
    Creates interactive visualizations and dashboards using Plotly.
    Generates executive-ready charts with proper styling and annotations.
    """

    def __init__(self, llm: ChatOpenAI):
        super().__init__(llm, "VisualizationAgent")

        self.chart_prompt = PromptTemplate(
            template="""
            You are an expert data visualization designer for executive dashboards.

            Based on the data and query intent, recommend the best visualization approach.

            DATA COLUMNS: {columns}
            DATA STATISTICS: {statistics}
            USER INTENT: {user_intent}
            METRICS REQUESTED: {metrics}

            Recommend:
            1. CHART_TYPE: (bar, line, scatter, pie, heatmap, treemap, funnel, gauge)
            2. X_AXIS: Column for x-axis
            3. Y_AXIS: Column(s) for y-axis
            4. COLOR_BY: Column for color grouping (optional)
            5. TITLE: Chart title
            6. ANNOTATIONS: Key points to highlight

            Return as JSON.
            """,
            input_variables=["columns", "statistics", "user_intent", "metrics"]
        )

        self.chain = self.chart_prompt | llm | JsonOutputParser()
        self.repl = PythonREPL()

    def execute(self, state: OrchestrationState) -> Dict[str, Any]:
        self.log_execution("Generating visualizations...")

        processed_data = state.get("processed_data", {})
        query_intent = state.get("query_intent", {})

        try:
            # Get chart recommendations
            chart_spec = self.chain.invoke({
                "columns": json.dumps(processed_data.get("columns", [])),
                "statistics": json.dumps(processed_data.get("statistics", {})),
                "user_intent": query_intent.get("PRIMARY_INTENT", "data_retrieval"),
                "metrics": json.dumps(query_intent.get("METRICS", []))
            })

            # Generate chart
            chart_json = self._generate_chart(processed_data, chart_spec)

            return {
                "visualizations": [chart_json] if chart_json else [],
                "agent_outputs": {
                    "VisualizationAgent": chart_spec
                }
            }

        except Exception as e:
            self.log_execution(f"Visualization error: {str(e)}")
            return {
                "visualizations": [],
                "error_log": [f"VisualizationAgent error: {str(e)}"]
            }

    def _generate_chart(self, processed_data: Dict, chart_spec: Dict) -> Optional[Dict]:
        """Generate a Plotly chart based on the specification."""
        try:
            primary_result = processed_data.get("primary_result", {})
            if not primary_result:
                return None

            df = pd.DataFrame(primary_result)

            if df.empty:
                return None

            chart_type = chart_spec.get("CHART_TYPE", "bar")
            x_col = chart_spec.get("X_AXIS", df.columns[0] if len(df.columns) > 0 else None)
            y_col = chart_spec.get("Y_AXIS", df.columns[1] if len(df.columns) > 1 else None)
            title = chart_spec.get("TITLE", "Data Visualization")

            if not x_col or not y_col:
                return None

            # Create the appropriate chart
            if chart_type == "bar":
                fig = px.bar(df, x=x_col, y=y_col, title=title)
            elif chart_type == "line":
                fig = px.line(df, x=x_col, y=y_col, title=title)
            elif chart_type == "scatter":
                fig = px.scatter(df, x=x_col, y=y_col, title=title)
            elif chart_type == "pie":
                fig = px.pie(df, names=x_col, values=y_col, title=title)
            else:
                fig = px.bar(df, x=x_col, y=y_col, title=title)

            # Apply theme
            fig.update_layout(
                template=Config.CHART_THEME,
                font=dict(size=12),
                title_font=dict(size=16)
            )

            # Convert to JSON
            return json.loads(pio.to_json(fig))

        except Exception as e:
            self.log_execution(f"Chart generation error: {str(e)}")
            return None


class ReportGeneratorAgent(BaseAgent):
    """
    Generates comprehensive executive reports combining all insights.
    Creates C-suite ready documents with actionable recommendations.
    """

    def __init__(self, llm: ChatOpenAI):
        super().__init__(llm, "ReportGeneratorAgent")

        self.report_prompt = PromptTemplate(
            template="""
            You are an expert business analyst creating an executive report.

            Based on all the analysis performed, create a comprehensive executive summary.

            ORIGINAL QUERY: {user_query}

            DATA SUMMARY:
            {data_summary}

            INSIGHTS DISCOVERED:
            {insights}

            ALERTS & ANOMALIES:
            {alerts}

            FORECASTS:
            {forecasts}

            Create an executive report with:

            1. EXECUTIVE_SUMMARY: 2-3 paragraph overview for C-suite
            2. KEY_FINDINGS: Top 5 most important discoveries (bullet points)
            3. RISK_ASSESSMENT: Current risks and their potential impact
            4. OPPORTUNITIES: Growth or improvement opportunities identified
            5. RECOMMENDATIONS: Prioritized action items
            6. NEXT_STEPS: Immediate actions to take
            7. DATA_QUALITY_NOTES: Any caveats about the data or analysis

            Write in a professional, executive-friendly tone. Be concise but comprehensive.
            Return as JSON.
            """,
            input_variables=["user_query", "data_summary", "insights", "alerts", "forecasts"]
        )

        self.chain = self.report_prompt | llm | JsonOutputParser()

    def execute(self, state: OrchestrationState) -> Dict[str, Any]:
        self.log_execution("Generating executive report...")

        try:
            # Gather all insights
            insights = state.get("insights", [])
            alerts = state.get("anomalies_detected", [])
            forecasts = state.get("forecasts", {})
            processed_data = state.get("processed_data", {})

            # Generate report
            report_content = self.chain.invoke({
                "user_query": state["user_query"],
                "data_summary": json.dumps({
                    "row_count": processed_data.get("row_count", 0),
                    "columns": processed_data.get("columns", []),
                    "statistics": processed_data.get("statistics", {})
                }),
                "insights": json.dumps([i.to_dict() if isinstance(i, BusinessInsight) else i for i in insights]),
                "alerts": json.dumps([a.to_dict() if isinstance(a, Alert) else a for a in alerts]),
                "forecasts": json.dumps(forecasts)
            })

            # Create executive report object
            report = ExecutiveReport(
                report_id=hashlib.md5(state["user_query"].encode()).hexdigest()[:8],
                title=f"Business Intelligence Report",
                executive_summary=report_content.get("EXECUTIVE_SUMMARY", ""),
                key_metrics=state.get("kpi_metrics", {}),
                insights=insights,
                alerts=alerts,
                visualizations=state.get("visualizations", []),
                recommendations=report_content.get("RECOMMENDATIONS", [])
            )

            return {
                "executive_report": report,
                "agent_outputs": {
                    "ReportGeneratorAgent": report_content
                },
                "messages": [AIMessage(
                    content=self._format_report_markdown(report_content),
                    name="ReportGeneratorAgent"
                )]
            }

        except Exception as e:
            self.log_execution(f"Report generation error: {str(e)}")
            return {
                "error_log": [f"ReportGeneratorAgent error: {str(e)}"]
            }

    def _format_report_markdown(self, report: Dict) -> str:
        """Format the report as markdown for display."""
        md = "# Executive Business Intelligence Report\n\n"

        md += "## Executive Summary\n"
        md += report.get("EXECUTIVE_SUMMARY", "No summary available.") + "\n\n"

        md += "## Key Findings\n"
        for finding in report.get("KEY_FINDINGS", []):
            md += f"- {finding}\n"
        md += "\n"

        md += "## Risk Assessment\n"
        md += report.get("RISK_ASSESSMENT", "No risks identified.") + "\n\n"

        md += "## Opportunities\n"
        md += report.get("OPPORTUNITIES", "No opportunities identified.") + "\n\n"

        md += "## Recommendations\n"
        for rec in report.get("RECOMMENDATIONS", []):
            md += f"1. {rec}\n"
        md += "\n"

        md += "## Next Steps\n"
        for step in report.get("NEXT_STEPS", []):
            md += f"- {step}\n"

        return md


# =============================================================================
# SUPERVISOR & ORCHESTRATION LOGIC
# =============================================================================

class SupervisorAgent:
    """
    Central orchestration supervisor that coordinates all specialized agents.
    Implements intelligent routing and workflow management.
    """

    def __init__(self, llm: ChatOpenAI, agents: Dict[str, BaseAgent]):
        self.llm = llm
        self.agents = agents
        self.logger = logging.getLogger("Supervisor")

        self.routing_prompt = PromptTemplate(
            template="""
            You are the supervisor of an enterprise Business Intelligence AI system.

            You are managing these specialized agents:
            {agent_descriptions}

            Current workflow status:
            - Completed agents: {completed_agents}
            - Current insights count: {insight_count}
            - Alerts generated: {alert_count}
            - Original query intent: {query_intent}

            User's original request: {user_query}

            Based on what has been done and what still needs to be done,
            determine the next agent to invoke OR if we should FINISH.

            Consider:
            1. Have we gathered the necessary data?
            2. Have we performed the requested analysis?
            3. Did the user request visualizations?
            4. Should we generate a report?

            Return JSON with:
            - "next": Agent name or "FINISH"
            - "reasoning": Brief explanation of your decision
            """,
            input_variables=["agent_descriptions", "completed_agents", "insight_count",
                           "alert_count", "query_intent", "user_query"]
        )

        self.chain = self.routing_prompt | llm | JsonOutputParser()

    def route(self, state: OrchestrationState) -> str:
        """Determine the next agent to invoke."""
        self.logger.info("Supervisor routing decision...")

        agent_descriptions = "\n".join([
            f"- {name}: {agent.__class__.__doc__[:100]}..."
            for name, agent in self.agents.items()
        ])

        completed = list(state.get("agent_outputs", {}).keys())

        try:
            decision = self.chain.invoke({
                "agent_descriptions": agent_descriptions,
                "completed_agents": ", ".join(completed) if completed else "None",
                "insight_count": len(state.get("insights", [])),
                "alert_count": len(state.get("anomalies_detected", [])),
                "query_intent": json.dumps(state.get("query_intent", {})),
                "user_query": state["user_query"]
            })

            next_agent = decision.get("next", "FINISH")
            self.logger.info(f"Routing to: {next_agent} - {decision.get('reasoning', '')}")

            return next_agent

        except Exception as e:
            self.logger.error(f"Routing error: {str(e)}")
            return "FINISH"


# =============================================================================
# WORKFLOW GRAPH CONSTRUCTION
# =============================================================================

def create_bi_orchestration_workflow(db_path: str) -> StateGraph:
    """
    Create the complete BI orchestration workflow using LangGraph.

    Args:
        db_path: Path to the SQLite database

    Returns:
        Compiled LangGraph workflow
    """

    # Initialize environment
    initialize_environment()

    # Create LLM instances
    analytical_llm = ChatOpenAI(model=Config.PRIMARY_MODEL, temperature=Config.TEMPERATURE_ANALYTICAL)
    creative_llm = ChatOpenAI(model=Config.PRIMARY_MODEL, temperature=Config.TEMPERATURE_CREATIVE)

    # Initialize agents
    agents = {
        "QueryIntentAgent": QueryIntentAgent(analytical_llm),
        "DataRetrievalAgent": DataRetrievalAgent(analytical_llm, db_path),
        "AnomalyDetectionAgent": AnomalyDetectionAgent(analytical_llm),
        "ForecastingAgent": ForecastingAgent(creative_llm),
        "KPIMonitorAgent": KPIMonitorAgent(analytical_llm),
        "VisualizationAgent": VisualizationAgent(analytical_llm),
        "ReportGeneratorAgent": ReportGeneratorAgent(creative_llm)
    }

    # Initialize supervisor
    supervisor = SupervisorAgent(analytical_llm, agents)

    # Create node functions
    def query_intent_node(state: OrchestrationState) -> Dict:
        logger.info("---QUERY INTENT ANALYSIS---")
        result = agents["QueryIntentAgent"].execute(state)
        return {**result, "current_agent": "QueryIntentAgent", "num_steps": state.get("num_steps", 0) + 1}

    def data_retrieval_node(state: OrchestrationState) -> Dict:
        logger.info("---DATA RETRIEVAL---")
        result = agents["DataRetrievalAgent"].execute(state)
        return {**result, "current_agent": "DataRetrievalAgent", "num_steps": state.get("num_steps", 0) + 1}

    def anomaly_detection_node(state: OrchestrationState) -> Dict:
        logger.info("---ANOMALY DETECTION---")
        result = agents["AnomalyDetectionAgent"].execute(state)
        return {**result, "current_agent": "AnomalyDetectionAgent", "num_steps": state.get("num_steps", 0) + 1}

    def forecasting_node(state: OrchestrationState) -> Dict:
        logger.info("---FORECASTING---")
        result = agents["ForecastingAgent"].execute(state)
        return {**result, "current_agent": "ForecastingAgent", "num_steps": state.get("num_steps", 0) + 1}

    def kpi_monitor_node(state: OrchestrationState) -> Dict:
        logger.info("---KPI MONITORING---")
        result = agents["KPIMonitorAgent"].execute(state)
        return {**result, "current_agent": "KPIMonitorAgent", "num_steps": state.get("num_steps", 0) + 1}

    def visualization_node(state: OrchestrationState) -> Dict:
        logger.info("---VISUALIZATION---")
        result = agents["VisualizationAgent"].execute(state)
        return {**result, "current_agent": "VisualizationAgent", "num_steps": state.get("num_steps", 0) + 1}

    def report_generator_node(state: OrchestrationState) -> Dict:
        logger.info("---REPORT GENERATION---")
        result = agents["ReportGeneratorAgent"].execute(state)
        return {**result, "current_agent": "ReportGeneratorAgent", "num_steps": state.get("num_steps", 0) + 1}

    def supervisor_node(state: OrchestrationState) -> Dict:
        logger.info("---SUPERVISOR---")
        next_agent = supervisor.route(state)
        return {"next_agent": next_agent}

    def final_output_node(state: OrchestrationState) -> Dict:
        logger.info("---FINAL OUTPUT---")
        return {"workflow_status": "completed"}

    # Build workflow graph
    workflow = StateGraph(OrchestrationState)

    # Add nodes
    workflow.add_node("query_intent", query_intent_node)
    workflow.add_node("data_retrieval", data_retrieval_node)
    workflow.add_node("anomaly_detection", anomaly_detection_node)
    workflow.add_node("forecasting", forecasting_node)
    workflow.add_node("kpi_monitor", kpi_monitor_node)
    workflow.add_node("visualization", visualization_node)
    workflow.add_node("report_generator", report_generator_node)
    workflow.add_node("supervisor", supervisor_node)
    workflow.add_node("final_output", final_output_node)

    # Set entry point
    workflow.set_entry_point("query_intent")

    # Add edges
    workflow.add_edge("query_intent", "data_retrieval")
    workflow.add_edge("data_retrieval", "supervisor")

    # Conditional routing from supervisor
    def route_from_supervisor(state: OrchestrationState) -> str:
        next_agent = state.get("next_agent", "FINISH")

        agent_mapping = {
            "AnomalyDetectionAgent": "anomaly_detection",
            "ForecastingAgent": "forecasting",
            "KPIMonitorAgent": "kpi_monitor",
            "VisualizationAgent": "visualization",
            "ReportGeneratorAgent": "report_generator",
            "DataRetrievalAgent": "data_retrieval",
            "FINISH": "final_output"
        }

        return agent_mapping.get(next_agent, "final_output")

    workflow.add_conditional_edges(
        "supervisor",
        route_from_supervisor,
        {
            "anomaly_detection": "anomaly_detection",
            "forecasting": "forecasting",
            "kpi_monitor": "kpi_monitor",
            "visualization": "visualization",
            "report_generator": "report_generator",
            "data_retrieval": "data_retrieval",
            "final_output": "final_output"
        }
    )

    # All analysis agents route back to supervisor
    for agent_node in ["anomaly_detection", "forecasting", "kpi_monitor", "visualization"]:
        workflow.add_edge(agent_node, "supervisor")

    # Report generator goes to final output
    workflow.add_edge("report_generator", "final_output")
    workflow.add_edge("final_output", END)

    # Compile with memory
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)

    return app


# =============================================================================
# MAIN EXECUTION & DEMO
# =============================================================================

class EnterpriseBIOrchestrator:
    """
    High-level interface for the Enterprise BI Orchestration system.
    Provides a simple API for running business intelligence queries.
    """

    def __init__(self, db_path: str = "sqlite:///data/database-sql-transactions/leads_scored.db"):
        self.db_path = db_path
        self.workflow = None
        self.session_id = hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8]
        self.logger = logging.getLogger("EnterpriseBIOrchestrator")

    def initialize(self):
        """Initialize the orchestration workflow."""
        self.logger.info("Initializing Enterprise BI Orchestration System...")
        self.workflow = create_bi_orchestration_workflow(self.db_path)
        self.logger.info("System initialized successfully.")

    def query(self, user_query: str, config: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Execute a business intelligence query through the orchestration system.

        Args:
            user_query: Natural language business query
            config: Optional configuration overrides

        Returns:
            Complete analysis results including insights, alerts, and reports
        """
        if not self.workflow:
            self.initialize()

        self.logger.info(f"Processing query: {user_query[:100]}...")

        # Prepare initial state
        initial_state = {
            "user_query": user_query,
            "query_intent": {},
            "messages": [HumanMessage(content=user_query)],
            "chat_history": [],
            "data_sources": [],
            "raw_data": {},
            "processed_data": {},
            "sql_queries": [],
            "query_results": [],
            "kpi_metrics": {},
            "anomalies_detected": [],
            "forecasts": {},
            "insights": [],
            "executive_report": None,
            "visualizations": [],
            "current_agent": "",
            "next_agent": "",
            "agent_outputs": {},
            "workflow_status": "running",
            "error_log": [],
            "num_steps": 0
        }

        # Execute workflow
        run_config = {
            "configurable": {"thread_id": self.session_id},
            "recursion_limit": 15
        }

        if config:
            run_config.update(config)

        try:
            result = self.workflow.invoke(initial_state, run_config)

            self.logger.info(f"Query completed in {result.get('num_steps', 0)} steps")

            return {
                "success": True,
                "query": user_query,
                "insights": [i.to_dict() if isinstance(i, BusinessInsight) else i
                           for i in result.get("insights", [])],
                "alerts": [a.to_dict() if isinstance(a, Alert) else a
                          for a in result.get("anomalies_detected", [])],
                "forecasts": result.get("forecasts", {}),
                "visualizations": result.get("visualizations", []),
                "kpi_metrics": result.get("kpi_metrics", {}),
                "report": result.get("agent_outputs", {}).get("ReportGeneratorAgent", {}),
                "sql_queries": result.get("sql_queries", []),
                "execution_steps": result.get("num_steps", 0)
            }

        except Exception as e:
            self.logger.error(f"Query execution failed: {str(e)}")
            return {
                "success": False,
                "query": user_query,
                "error": str(e)
            }

    def stream_query(self, user_query: str):
        """
        Stream query execution for real-time updates.
        Yields intermediate results as they become available.
        """
        if not self.workflow:
            self.initialize()

        initial_state = {
            "user_query": user_query,
            "query_intent": {},
            "messages": [HumanMessage(content=user_query)],
            "chat_history": [],
            "data_sources": [],
            "raw_data": {},
            "processed_data": {},
            "sql_queries": [],
            "query_results": [],
            "kpi_metrics": {},
            "anomalies_detected": [],
            "forecasts": {},
            "insights": [],
            "executive_report": None,
            "visualizations": [],
            "current_agent": "",
            "next_agent": "",
            "agent_outputs": {},
            "workflow_status": "running",
            "error_log": [],
            "num_steps": 0
        }

        run_config = {
            "configurable": {"thread_id": self.session_id},
            "recursion_limit": 15
        }

        for step in self.workflow.stream(initial_state, run_config):
            yield step


# =============================================================================
# DEMO & USAGE EXAMPLES
# =============================================================================

def run_demo():
    """
    Demonstrate the Enterprise BI Orchestration system with sample queries.
    """

    print("=" * 80)
    print("ENTERPRISE BUSINESS INTELLIGENCE AI ORCHESTRATION SYSTEM")
    print("=" * 80)
    print()

    # Initialize orchestrator
    orchestrator = EnterpriseBIOrchestrator(
        db_path="sqlite:///data/database-sql-transactions/leads_scored.db"
    )

    # Demo queries showcasing different capabilities
    demo_queries = [
        # Query 1: Data Analysis with KPI Monitoring
        """
        Analyze our customer transactions from the past year.
        Identify the top 10 customers by purchase probability (p1 score).
        Monitor key revenue KPIs and flag any concerning trends.
        """,

        # Query 2: Anomaly Detection & Forecasting
        """
        Detect any anomalies in our sales patterns across product categories.
        Provide a forecast for the next quarter and identify any risks.
        Generate an executive summary with recommended actions.
        """,

        # Query 3: Comprehensive Executive Report
        """
        Generate a comprehensive business intelligence report covering:
        1. Revenue performance by product
        2. Customer acquisition and retention metrics
        3. Lead scoring effectiveness
        4. Recommendations for growth
        Include visualizations and an executive summary.
        """
    ]

    print("Running Demo Queries...")
    print("-" * 80)

    for i, query in enumerate(demo_queries, 1):
        print(f"\n{'='*80}")
        print(f"DEMO QUERY {i}")
        print(f"{'='*80}")
        print(f"Query: {query.strip()}")
        print("-" * 40)

        # Execute query
        result = orchestrator.query(query)

        if result["success"]:
            print(f"\n✓ Query completed successfully in {result['execution_steps']} steps")

            print(f"\nInsights Generated: {len(result['insights'])}")
            for insight in result['insights'][:3]:  # Show first 3
                print(f"  - [{insight.get('type', 'N/A')}] {insight.get('title', 'N/A')}")

            print(f"\nAlerts Generated: {len(result['alerts'])}")
            for alert in result['alerts'][:3]:  # Show first 3
                print(f"  - [{alert.get('severity', 'N/A')}] {alert.get('message', 'N/A')[:60]}...")

            print(f"\nKPI Metrics: {len(result['kpi_metrics'])}")
            for kpi, value in list(result['kpi_metrics'].items())[:5]:
                print(f"  - {kpi}: {value:.2f}" if isinstance(value, (int, float)) else f"  - {kpi}: {value}")

            if result['report']:
                print("\n📊 Executive Report Generated")
                exec_summary = result['report'].get('EXECUTIVE_SUMMARY', '')[:200]
                print(f"Summary: {exec_summary}...")
        else:
            print(f"\n✗ Query failed: {result.get('error', 'Unknown error')}")

        print("\n" + "-" * 80)


if __name__ == "__main__":
    # Run the demo
    run_demo()

    # Interactive mode example
    print("\n" + "=" * 80)
    print("INTERACTIVE MODE")
    print("=" * 80)
    print("\nYou can now use the orchestrator programmatically:")
    print()
    print("from enterprise_bi_ai_orchestration import EnterpriseBIOrchestrator")
    print()
    print("orchestrator = EnterpriseBIOrchestrator('your_database.db')")
    print("result = orchestrator.query('Your business question here')")
    print()
    print("# For streaming results:")
    print("for step in orchestrator.stream_query('Your question'):")
    print("    print(step)")
